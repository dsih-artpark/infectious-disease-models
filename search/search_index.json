{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Generalized Compartmental Modeling Framework","text":"<p>This documentation describes a modular, configurable framework for defining, simulating, and calibrating compartmental epidemiological models (SIR, SEIR, SIS, SIRS, SEIRS, and more).</p> <p>The framework is driven by a YAML configuration file and supports: - Arbitrary compartment structures and transition expressions - Dynamic ODE generation from transition rules - Simulation with <code>scipy.integrate.odeint</code> - Noise injection and sub-sampling for realistic observations - Parameter estimation using classical optimizers (Nelder\u2013Mead, BFGS, L-BFGS-B, Basin-Hopping) - Bayesian calibration via MCMC (emcee) - Diagnostics, loss landscapes, and posterior analysis</p> <p>Use the left navigation to explore the YAML specification, usage examples, extensibility notes, and debugging tips.</p>"},{"location":"references/","title":"References","text":"<p>A collection of external resources related to epidemiological modeling and this framework.</p> <ul> <li> <p>EMOD &amp; emodpy-malaria documentation \u2014 Comprehensive guide for IDM\u2019s epidemiological modeling tools. https://docs.idmod.org/projects/emodpy-malaria/en/latest/index.html</p> </li> <li> <p>SciPy Documentation \u2014 Numerical computing library used for ODE solvers and optimization. https://docs.scipy.org/doc/scipy/</p> </li> <li> <p>emcee Documentation \u2014 Affine-invariant MCMC ensemble sampler in Python. https://emcee.readthedocs.io/</p> </li> <li> <p>Matplotlib Documentation \u2014 Plotting library used to visualize simulations and results. https://matplotlib.org/stable/contents.html</p> </li> <li> <p>PyYAML Documentation \u2014 YAML parser for loading model configurations. https://pyyaml.org/wiki/PyYAMLDocumentation</p> </li> </ul>"},{"location":"configuration/yaml_config/","title":"YAML Configuration Format","text":"<p>The framework is configured entirely via a YAML file. Below are the supported fields and an example.</p>"},{"location":"configuration/yaml_config/#global-settings","title":"Global Settings","text":"<ul> <li><code>days</code> (int): number of days to simulate.</li> <li><code>noise_std</code> (float): standard deviation of Gaussian noise added to trajectories.</li> <li><code>subset_ratio</code> (float): fraction of time points to randomly sample for fitting (0.0 - 1.0).</li> <li><code>optimizers</code> (list[str]): which optimizers to run (e.g., Nelder-Mead, BFGS, L-BFGS-B).</li> <li><code>fit_compartments</code> (list[str], optional): compartments included in the loss (default: ['I']).</li> </ul>"},{"location":"configuration/yaml_config/#model-definition","title":"Model Definition","text":"<p>Each model block has: - <code>compartments</code>: list of compartment names (strings). - <code>parameters</code>: map of parameter names to initial values. - <code>transitions</code>: map of <code>FROM-&gt;TO</code> to a rate expression (use parameter names and compartment names). - <code>population</code>: integer N (used in expressions). - <code>initial_conditions</code>: map of compartment initial values. - <code>assumptions</code>: (string) optional description.</p>"},{"location":"configuration/yaml_config/#example-sir-model","title":"Example: SIR model","text":"<pre><code>days: 160\nnoise_std: 2.0\nsubset_ratio: 0.4\noptimizers:\n  - Nelder-Mead\n  - BFGS\n  - L-BFGS-B\nfit_compartments: [I]\n\nSIR_model:\n  compartments: [S, I, R]\n  parameters:\n    beta: 0.3\n    gamma: 0.1\n  transitions:\n    S-&gt;I: beta * S * I / N\n    I-&gt;R: gamma * I\n  population: 1000\n  initial_conditions:\n    S: 990\n    I: 10\n    R: 0\n  assumptions: Closed population, permanent immunity\n</code></pre>"},{"location":"configuration/yaml_config/#syntax-rules","title":"Syntax rules","text":"<ul> <li>Use Python-style arithmetic in transition expressions (e.g. <code>beta * S * I / N</code>).</li> <li>Division by <code>N</code> is explicit; include <code>N</code> in expressions when needed.</li> <li>Parameter names and compartment names are case-sensitive.</li> <li>You may add additional model blocks in the same file for batch simulations.</li> </ul>"},{"location":"debugging/improvements/","title":"Improvements","text":"<ul> <li>Relaxed prior bounds to encourage better exploration.</li> <li>Smarter walker initialization (spread inside prior region).</li> <li>Added checks to skip parameter sets that produce unstable ODE solutions.</li> <li>Improved plotting routines: explicit <code>savefig()</code> and <code>plt.close()</code> to prevent file locking.</li> <li>Exposed hooks to allow custom loss functions and time-varying parameters.</li> </ul>"},{"location":"debugging/issues_encountered/","title":"Issues Encountered","text":""},{"location":"debugging/issues_encountered/#1-numerical-instability-nans","title":"1. Numerical instability / NaNs","text":"<ul> <li>ODE solver can produce NaNs for extreme parameter values.</li> <li>Fixes: check parameter bounds, improve initialization, catch exceptions and return large loss.</li> </ul>"},{"location":"debugging/issues_encountered/#2-stiff-dynamics","title":"2. Stiff dynamics","text":"<ul> <li>Some parameter regimes are stiff (very small or large rates).</li> <li>Fixes: use a stiff solver (e.g., <code>scipy.integrate.solve_ivp</code> with <code>method='BDF'</code>), tighten tolerances.</li> </ul>"},{"location":"debugging/issues_encountered/#3-overfitting-to-noise","title":"3. Overfitting to noise","text":"<ul> <li>Deterministic optimizers can pick parameters that explain a particular noise realization.</li> <li>Fixes: regularize loss, fit across multiple noise realizations, or use Bayesian inference.</li> </ul>"},{"location":"debugging/issues_encountered/#4-mcmc-walker-initialization-problems","title":"4. MCMC walker initialization problems","text":"<ul> <li>Walkers outside priors cause immediate failure.</li> <li>Fixes: sample initial walker positions from a distribution strictly inside priors.</li> </ul>"},{"location":"dev/","title":"Developer Guide","text":"<p>This guide is for developers and contributors who want to understand the internal architecture of the Generalized Compartmental Modeling Framework.</p> <p>The User-facing pages explain how to run models and interpret results, but this section focuses on the code internals \u2014 how modules, classes, and functions work together.</p>"},{"location":"dev/#purpose","title":"Purpose","text":"<p>The Developer Guide will help you: - Understand the structure and flow of the codebase - Extend the framework with new models, fitting methods, or visualizations - Maintain and debug existing functionality</p>"},{"location":"dev/#high-level-architecture","title":"High-Level Architecture","text":"<p>The framework follows a modular design:</p> <ol> <li>Main Controller (<code>main.py</code>) </li> <li>Parses CLI arguments (<code>--model &lt;model_name&gt;</code>)  </li> <li>Loads the YAML configuration  </li> <li> <p>Orchestrates the workflow: simulation \u2192 noise injection \u2192 sampling \u2192 calibration \u2192 plotting \u2192 saving outputs  </p> </li> <li> <p>Core Model Logic (<code>model.py</code>) </p> </li> <li><code>Population</code> \u2014 Population size &amp; assumptions  </li> <li> <p><code>CompartmentalModel</code> \u2014 Builds and simulates the ODE system  </p> </li> <li> <p>Calibration Layer (<code>calibration.py</code>) </p> </li> <li>Optimization (Nelder-Mead, BFGS, L-BFGS-B, etc.)  </li> <li>MCMC for Bayesian inference  </li> <li> <p>Loss calculation functions  </p> </li> <li> <p>Plotting Layer (<code>plotting.py</code>) </p> </li> <li>Generates simulation plots, noisy data plots, comparisons, parameter estimation graphs, and MCMC corner plots  </li> </ol>"},{"location":"dev/#workflow-for-developers","title":"Workflow for Developers","text":"<ol> <li>Add or modify models in the YAML configuration  </li> <li>Update model logic in <code>model.py</code> if new compartments or transitions are needed  </li> <li>Extend calibration methods in <code>calibration.py</code> for new fitting techniques  </li> <li>Enhance visualization in <code>plotting.py</code> for additional plots or formats  </li> <li>Test your changes with:     <pre><code>python main.py --model &lt;model_name&gt;\n</code></pre></li> </ol>"},{"location":"dev/calibration/","title":"calibration.py \u2014 Parameter Fitting and MCMC","text":"<p>This module implements optimization-based and Bayesian parameter estimation.</p>"},{"location":"dev/calibration/#functions","title":"Functions","text":""},{"location":"dev/calibration/#loss_functiontheta-model-sampled_times-observed_data-fit_compartments","title":"<code>loss_function(theta, model, sampled_times, observed_data, fit_compartments)</code>","text":"<p>Computes the loss between simulated and observed data for selected compartments.</p> <p>Parameters - <code>theta</code> (list[float]) \u2014 Parameter vector. - <code>model</code> (CompartmentalModel) \u2014 Model to simulate. - <code>sampled_times</code> (list[float]) \u2014 Time points used for fitting. - <code>observed_data</code> (np.ndarray) \u2014 Observed noisy data. - <code>fit_compartments</code> (list[str]) \u2014 Compartments included in the loss.</p>"},{"location":"dev/calibration/#fit_with_optimizersmodel-optimizers","title":"<code>fit_with_optimizers(model, optimizers, ...)</code>","text":"<p>Runs selected optimizers (e.g., Nelder-Mead, BFGS, L-BFGS-B) to fit parameters.</p>"},{"location":"dev/calibration/#run_mcmcmodel","title":"<code>run_mcmc(model, ...)</code>","text":"<p>Uses the emcee sampler to estimate parameter posterior distributions.</p> <p>Workflow 1. Define prior bounds. 2. Initialize walkers inside bounds. 3. Simulate the model and compute log-likelihood. 4. Save and plot posterior samples.</p>"},{"location":"dev/calibration/#example-usage","title":"Example Usage","text":"<pre><code>```python\nfrom calibration import fit_with_optimizers\n\nresults = fit_with_optimizers(model, [\"BFGS\", \"Nelder-Mead\"], ...)\n```\n</code></pre>"},{"location":"dev/model/","title":"model.py \u2014 Core Model Classes","text":"<p>This module defines the primary classes used for simulation: Population and CompartmentalModel.</p>"},{"location":"dev/model/#population-class","title":"Population Class","text":""},{"location":"dev/model/#purpose","title":"Purpose","text":"<p>Represents the population in which the epidemic model is simulated and validates initial conditions.</p>"},{"location":"dev/model/#attributes","title":"Attributes","text":"<ul> <li><code>N</code> (int) \u2014 Total population size.</li> <li><code>assumptions</code> (str, optional) \u2014 Description of model assumptions.</li> </ul>"},{"location":"dev/model/#methods","title":"Methods","text":"<ul> <li><code>__init__(self, N, assumptions=None)</code>   Validates that <code>N &gt; 0</code>. Stores population size and optional assumptions.</li> <li><code>__repr__(self)</code>   Returns a human-readable summary.</li> </ul>"},{"location":"dev/model/#compartmentalmodel-class","title":"CompartmentalModel Class","text":""},{"location":"dev/model/#purpose_1","title":"Purpose","text":"<p>Encapsulates all model logic: ODE simulation, noise injection, and timepoint sampling.</p>"},{"location":"dev/model/#attributes_1","title":"Attributes","text":"<ul> <li><code>compartments</code> (list[str]) \u2014 Names of model compartments.</li> <li><code>parameters</code> (dict) \u2014 Parameter name \u2192 value.</li> <li><code>transitions</code> (dict) \u2014 Mapping <code>FROM-&gt;TO</code> \u2192 expression string.</li> <li><code>population</code> (Population) \u2014 Linked Population object.</li> <li><code>initial_conditions</code> (dict) \u2014 Initial values for each compartment.</li> </ul>"},{"location":"dev/model/#key-methods","title":"Key Methods","text":"<ul> <li><code>compute_transition_rates(self, y, params)</code>   Parses transitions and evaluates rates for given state and parameters.</li> <li><code>compute_rhs(self, t, y, params)</code>   Constructs the system of ODEs (<code>dC/dt</code>).</li> <li><code>simulate(self, y0, t, params)</code>   Integrates the ODE system using <code>odeint</code> or <code>solve_ivp</code>.</li> <li><code>add_noise(self, trajectories, sigma)</code>   Adds Gaussian noise to simulation outputs.</li> <li><code>sample_timepoints(self, trajectories, ratio)</code>   Randomly selects observation points for parameter fitting.</li> </ul>"},{"location":"dev/model/#example-usage","title":"Example Usage","text":"<pre><code>    from model import Population, CompartmentalModel\n\n    pop = Population(N=1000)\n    sir_model = CompartmentalModel(\n        compartments=[\"S\", \"I\", \"R\"],\n        parameters={\"beta\": 0.3, \"gamma\": 0.1},\n        transitions={\"S-&gt;I\": \"beta * S * I / N\", \"I-&gt;R\": \"gamma * I\"},\n        population=pop,\n        initial_conditions={\"S\": 990, \"I\": 10, \"R\": 0}\n    )\n\n    t, y = sir_model.simulate()\n</code></pre>"},{"location":"dev/plotting/","title":"plotting.py \u2014 Visualization Utilities","text":"<p>This module generates plots for simulation results, noisy data, parameter fits, and MCMC results.</p>"},{"location":"dev/plotting/#functions","title":"Functions","text":"<ul> <li><code>plot_simulation(traj, t, out_path)</code> \u2014 Plots clean simulation trajectories.</li> <li><code>plot_noisy(noisy_traj, sampled_points, out_path)</code> \u2014 Plots noisy observed data.</li> <li><code>plot_comparison(true_traj, fitted_traj, sampled_points, out_path)</code> \u2014 Compares fitted vs. true trajectories.</li> <li><code>parameter_estimation_plot(fit_results, out_path)</code> \u2014 Shows estimated parameters from optimizers.</li> <li><code>mcmc_corner_plot(samples, out_path)</code> \u2014 Corner plot of posterior parameter distributions.</li> </ul>"},{"location":"dev/plotting/#example-usage","title":"Example Usage","text":"<pre><code>    from plotting import plot_simulation\n\n    plot_simulation(traj, t, \"plots/SIR_model/plot_simulation.png\")\n</code></pre>"},{"location":"features/advanced_features/","title":"Advanced Features","text":"<ul> <li>Time-dependent parameters via <code>extras_fn(t, y)</code>.</li> <li>Selective observation model: fit only some compartments or use different noise models per compartment.</li> <li>Checkpointing: save intermediate parameter states during long runs.</li> <li>Loss landscape visualization: grid-evaluate loss over parameter pairs and contour plot in log-scale.</li> <li>Posterior diagnostics: corner plots (e.g., using <code>corner</code>), trace plots, autocorrelation.</li> </ul>"},{"location":"features/extensibility/","title":"Extensibility","text":"<p>This framework was designed to be extensible. Common extension points:</p>"},{"location":"features/extensibility/#1-new-compartment-models","title":"1. New compartment models","text":"<p>Add a new block in the YAML with compartments and transitions \u2014 no code changes needed.</p>"},{"location":"features/extensibility/#2-new-parameter-types","title":"2. New parameter types","text":"<p>Add parameters to the <code>parameters</code> map. For time-varying parameters, implement <code>extras_fn</code>.</p>"},{"location":"features/extensibility/#3-custom-loss-functions","title":"3. Custom loss functions","text":"<p>Provide a Python callable to compute the loss instead of MSE. For example, weighted MSE or Poisson log-likelihood for count data.</p>"},{"location":"features/extensibility/#4-metapopulation-network-models","title":"4. Metapopulation / Network models","text":"<ul> <li>Extend <code>transitions</code> syntax to include indices or use multiple population blocks.</li> <li>The ODE generator will need to be extended to create vectorized compartments per patch.</li> </ul>"},{"location":"features/extensibility/#5-new-optimizers-or-inference-engines","title":"5. New optimizers or inference engines","text":"<ul> <li>Add wrappers for other optimizers (e.g., CMA-ES, differential evolution).</li> <li>Add MCMC engines (e.g., PyMC, NumPyro) by mapping log-posterior.</li> </ul>"},{"location":"features/outputs/","title":"Outputs","text":"<p>The framework produces:</p>"},{"location":"features/outputs/#data-files-csv","title":"Data files (CSV)","text":"<p>Located in <code>data/&lt;model_name&gt;/</code>:</p> <ul> <li><code>true_data.csv</code> \u2014 clean simulation trajectories</li> <li><code>noisy_data.csv</code> \u2014 noisy observed trajectories</li> <li><code>time_points.csv</code> \u2014 sampled observation points used for fitting</li> </ul>"},{"location":"features/outputs/#plots-png","title":"Plots (PNG)","text":"<p>Located in <code>plots/&lt;model_name&gt;/</code>:</p> <ul> <li><code>plot_simulation.png</code> \u2014 clean trajectories of all compartments</li> <li><code>plot_noisy.png</code> \u2014 noisy simulated data</li> <li><code>plot_comparison.png</code> \u2014 fitted vs. true trajectories</li> <li><code>parameter_estimation.png</code> \u2014 fitted parameter summary</li> <li><code>mcmc_corner_plot.png</code> \u2014 posterior distributions (if MCMC is run)</li> </ul>"},{"location":"features/outputs/#recommended-directory-layout","title":"Recommended directory layout","text":"<pre><code>plots/\n  \u2514\u2500 SIR_model/\n      \u251c\u2500 plot_simulation.png\n      \u251c\u2500 plot_noisy.png\n      \u251c\u2500 plot_comparison.png\n      \u251c\u2500 parameter_estimation.png\n      \u2514\u2500 mcmc_corner_plot.png\n\ndata/\n  \u2514\u2500 SIR_model/\n      \u251c\u2500 true_data.csv\n      \u251c\u2500 noisy_data.csv\n      \u2514\u2500 time_points.csv\n</code></pre>"},{"location":"usage/noise_injection/","title":"Noise Injection","text":"<p>To simulate measurement noise, Gaussian noise is added to the clean trajectories:</p> \\[ y_{\\text{noisy}}(t) = y_{\\text{clean}}(t) + \\epsilon(t),\\quad \\epsilon(t)\\sim \\mathcal{N}(0, \\sigma^2) \\] <ul> <li><code>sigma</code> is configured via <code>noise_std</code> in the YAML.</li> <li>After adding noise, values are clipped to valid ranges (e.g., non-negative, \u2264 population).</li> <li>Optionally round to integers if modeling counts.</li> </ul>"},{"location":"usage/noise_injection/#example","title":"Example","text":"<pre><code>import numpy as np\n\ndef add_noise(traj, sigma, clip_min=0, clip_max=None, round_int=False):\n    noisy = traj + np.random.normal(0, sigma, traj.shape)\n    if clip_max is not None:\n        noisy = np.clip(noisy, clip_min, clip_max)\n    else:\n        noisy = np.clip(noisy, clip_min, None)\n    if round_int:\n        noisy = np.rint(noisy).astype(int)\n    return noisy\n</code></pre>"},{"location":"usage/parameter_fitting/","title":"Parameter Fitting","text":"<p>The framework supports deterministic optimizers and MCMC.</p>"},{"location":"usage/parameter_fitting/#loss-function","title":"Loss function","text":"<p>Default: mean squared error across chosen compartments and sampled time points.</p> \\[ L(\\theta) = \\frac{1}{n}\\sum_{i=1}^n \\sum_{c\\in C_{\\text{fit}}} \\big( y^{\\text{sim}}_c(t_i;\\theta) - y^{\\text{obs}}_c(t_i) \\big)^2 \\] <p><code>C_fit</code> defaults to <code>['I']</code> but can be set via <code>fit_compartments</code> in YAML.</p>"},{"location":"usage/parameter_fitting/#deterministic-optimizers","title":"Deterministic optimizers","text":"<p>Uses <code>scipy.optimize.minimize</code> with method: - <code>\"Nelder-Mead\"</code> (derivative-free) - <code>\"BFGS\"</code> (quasi-Newton) - <code>\"L-BFGS-B\"</code> (bounded, limited-memory)</p> <p>Example usage:</p> <pre><code>from scipy.optimize import minimize\n\ndef loss_fn(theta_vec):\n    # map theta_vec to parameters, simulate, compute MSE on sampled times\n    return mse\n\nres = minimize(loss_fn, x0=[0.2,0.1], method='L-BFGS-B', bounds=[(1e-6,5),(1e-6,5)])\n</code></pre>"},{"location":"usage/parameter_fitting/#basin-hopping","title":"Basin-hopping","text":"<p>Use <code>scipy.optimize.basinhopping</code> to escape local minima; internally runs a local optimizer.</p>"},{"location":"usage/parameter_fitting/#mcmc-emcee","title":"MCMC (emcee)","text":"<p>Set uniform priors (or others) and Gaussian likelihood assuming known noise std:</p> <pre><code>import emcee\ndef log_prior(theta):\n    beta, gamma = theta\n    if 0 &lt; beta &lt; 5 and 0 &lt; gamma &lt; 5:\n        return 0.0\n    return -np.inf\n\ndef log_likelihood(theta):\n    # simulate, compute gaussian log-likelihood with known sigma\n    return ll\n\ndef log_posterior(theta):\n    lp = log_prior(theta)\n    if not np.isfinite(lp):\n        return -np.inf\n    return lp + log_likelihood(theta)\n\nndim, nwalkers = 2, 32\np0 = 1e-3 + np.random.rand(nwalkers, ndim) * 0.1\nsampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior)\nsampler.run_mcmc(p0, 5000, progress=True)\n</code></pre> <p>Tips: - Ensure walkers are initialized inside prior bounds. - Filter out samples where simulation failed (NaN solutions). - Relax overly narrow priors during debugging.</p>"},{"location":"usage/simulation/","title":"Simulation","text":""},{"location":"usage/simulation/#from-transitions-to-odes","title":"From transitions to ODEs","text":"<p>Given compartments <code>[C1, C2, ..., Ck]</code> and transitions <code>A-&gt;B: expr</code>, we compute for each compartment the net rate:</p> <ul> <li>For <code>A</code> subtract <code>expr</code></li> <li>For <code>B</code> add <code>expr</code></li> </ul> <p>The result is a system:</p> \\[ \\frac{d\\mathbf{y}}{dt} = f(t, \\mathbf{y}; \\theta) \\] <p>where \\(\\mathbf{y} = [S, I, R, ...]\\) and \\(\\theta\\) are the parameters.</p>"},{"location":"usage/simulation/#solver","title":"Solver","text":"<p>The default solver is <code>scipy.integrate.odeint</code> (LSODA). Usage example:</p> <pre><code>from scipy.integrate import odeint\nimport numpy as np\n\ndef rhs(y, t, params):\n    S, I, R = y\n    beta, gamma = params['beta'], params['gamma']\n    N = params['N']\n    dSdt = -beta * S * I / N\n    dIdt = beta * S * I / N - gamma * I\n    dRdt = gamma * I\n    return [dSdt, dIdt, dRdt]\n\nt = np.linspace(0, days, days+1)\ny0 = [990, 10, 0]\nsol = odeint(rhs, y0, t, args=( {'beta':0.3,'gamma':0.1,'N':1000}, ))\n</code></pre>"},{"location":"usage/simulation/#time-dependent-parameters","title":"Time-dependent parameters","text":"<p>If your model requires time-varying parameters, provide an <code>extras_fn(t, y)</code> hook that returns a dict of parameter values at <code>t</code>. The <code>rhs</code> should consult those values when computing rates.</p>"},{"location":"usage/workflow/","title":"Workflow","text":"<p>High-level pipeline:</p> <pre><code>Define YAML \u2192 Generate ODEs \u2192 Simulate \u2192 Add Noise \u2192 Subset \u2192 Fit Parameters \u2192 Visualize &amp; Diagnose\n</code></pre>"},{"location":"usage/workflow/#steps","title":"Steps","text":"<ol> <li>Define YAML: create a model block with compartments, parameters, transitions, population, and initial conditions.</li> <li>Generate ODEs: the framework parses <code>transitions</code> into symbolic rates and constructs the right-hand side of the ODE system automatically.</li> <li>Simulate: integrate the ODE system (default: <code>scipy.integrate.odeint</code>) over the time grid <code>t = 0..days</code>.</li> <li>Add Noise: Gaussian noise is added to simulated trajectories and clipped to valid ranges.</li> <li>Subset Sampling: sample a fraction of time points (<code>subset_ratio</code>) to mimic sparse observations.</li> <li>Fit Parameters: minimize a loss function (default MSE over specified compartments) using chosen optimizers. Optionally run MCMC for posterior estimation.</li> <li>Visualize: produce trajectory plots, loss landscape, and posterior corner plots.</li> </ol>"},{"location":"usage/workflow/#cli-script-example","title":"CLI / Script Example","text":"<p>Run a specific model (defined in your YAML configuration) by name:</p> <pre><code>python main.py --model SIR_model\n</code></pre> <p>After running, you\u2019ll find all outputs in the <code>plots/&lt;model_name&gt;/</code> folder.</p>"}]}