{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Epidemic Modeling Framework","text":"<p>Welcome to the documentation for Epidemic Modeling Framework!</p>"},{"location":"#project-overview","title":"Project Overview","text":"<p>This project implements a flexible, configurable framework for simulating and fitting compartmental epidemiological models such as SIR, SEIR, SEIRS, etc.</p> <p>Features include: - ODE-based simulation - Synthetic noise injection - Parameter fitting via multiple optimizers - MCMC-based posterior sampling</p>"},{"location":"fitting/","title":"Parameter Fitting","text":"<p>The framework supports multiple optimization algorithms:</p> <ul> <li><code>Nelder-Mead</code>: Derivative-free</li> <li><code>BFGS</code>: Gradient-based</li> <li><code>L-BFGS-B</code>: BFGS with bounds</li> </ul> <p>Only a random subset of noisy data is used to simulate limited real-world</p>"},{"location":"future/","title":"Future Work","text":"<ul> <li>Add support for time-varying parameters</li> <li>Extend to networked or spatial compartment models</li> <li>Integrate real-world epidemic datasets</li> <li>Improve computational efficiency and parallelize MCMC</li> </ul>"},{"location":"install/","title":"Installation","text":"<ol> <li>Clone the repository:    ```bash    git clone     cd"},{"location":"mcmc/","title":"MCMC Calibration","text":"<p>Uses <code>emcee</code> to sample from the posterior distribution of parameters.</p> <p>Purpose: - Estimate uncertainty in parameters - Produce credible intervals - Visualize correlation with corner plots</p> <p>Initial parameter guess, priors, and likelihood are configurable.</p>"},{"location":"noise/","title":"Noise Injection","text":"<ul> <li>Add Gaussian noise to simulated data</li> <li>Simulates real-world measurement uncertainty</li> <li>Controlled by <code>noise_std</code> in config file</li> </ul> <p>Used to test robustness of parameter fitting.</p>"},{"location":"results/","title":"Results and Plots","text":"<p>Common plots include:</p> <ul> <li>Clean simulation (true trajectory)</li> <li>Noisy simulation (with synthetic noise)</li> <li>Fitted vs true trajectories</li> <li>Estimated vs true parameter values</li> <li>Corner plots from MCMC samples</li> </ul>"},{"location":"analysis/methodology/","title":"Methodology","text":""},{"location":"analysis/methodology/#problem-statement","title":"Problem Statement","text":"<p>Clear description of the problem being solved and the objectives.</p>"},{"location":"analysis/methodology/#approach","title":"Approach","text":"<p>Overview of the analytical approach and methodology.</p>"},{"location":"analysis/methodology/#mathematical-framework","title":"Mathematical Framework","text":""},{"location":"analysis/methodology/#key-equations","title":"Key Equations","text":"<p>Here are some example equations using LaTeX syntax:</p> <p>The mean squared error (MSE) is calculated as:</p> <p>$$ MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 $$</p> <p>For a linear regression model:</p> <p>$$ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n + \\epsilon $$</p>"},{"location":"analysis/methodology/#model-selection-criteria","title":"Model Selection Criteria","text":"<p>Description of how models are evaluated and selected.</p>"},{"location":"analysis/methodology/#feature-selection","title":"Feature Selection","text":"<ul> <li>Methods used for feature selection</li> <li>Feature importance metrics</li> <li>Selection criteria</li> </ul>"},{"location":"analysis/methodology/#validation-strategy","title":"Validation Strategy","text":"<ul> <li>Cross-validation approach</li> <li>Train-test split methodology</li> <li>Performance metrics</li> </ul>"},{"location":"analysis/methodology/#statistical-methods","title":"Statistical Methods","text":"<ul> <li>Statistical tests used</li> <li>Significance levels</li> <li>Assumptions</li> </ul>"},{"location":"analysis/methodology/#implementation-details","title":"Implementation Details","text":"<ul> <li>Software and libraries used</li> <li>Computational requirements</li> <li>Performance considerations </li> </ul>"},{"location":"data/dataset-description/","title":"Dataset Description","text":""},{"location":"data/dataset-description/#overview","title":"Overview","text":"<p>Brief description of the dataset, its source, and its relevance to the project.</p>"},{"location":"data/dataset-description/#data-sources","title":"Data Sources","text":"<ul> <li>Source 1: [Description and DS ID]</li> <li>Source 2: [Description and DS ID]</li> </ul>"},{"location":"data/dataset-description/#data-description","title":"Data Description","text":"<p>Description of the available data: - Time period - Spatial coverage - Data generating processes and assumptions</p>"},{"location":"data/dataset-description/#data-quality","title":"Data Quality","text":"<ul> <li>Missing values</li> <li>Data completeness</li> <li>Data accuracy</li> <li>Any known issues or limitations</li> </ul>"},{"location":"data/dataset-description/#data-size-and-structure","title":"Data Size and Structure","text":"<ul> <li>Number of records</li> <li>Number of features</li> <li>Data types</li> <li>File formats</li> </ul>"},{"location":"data/dataset-description/#data-updates","title":"Data Updates","text":"<ul> <li>Update frequency</li> <li>Last update date</li> <li>Change log </li> </ul>"},{"location":"data/exploratory-analysis/","title":"Exploratory Data Analysis (Spatio-Temporal)","text":""},{"location":"data/exploratory-analysis/#overview","title":"Overview","text":"<p>Briefly describe the goals of the exploratory analysis and the main questions being investigated.</p>"},{"location":"data/exploratory-analysis/#summary-statistics","title":"Summary Statistics","text":"<ul> <li>Overview of key variables</li> <li>Descriptive statistics (mean, median, std, min, max, etc.)</li> <li>Distribution of variables (histograms, boxplots)</li> </ul>"},{"location":"data/exploratory-analysis/#spatial-analysis","title":"Spatial Analysis","text":"<ul> <li>Description of spatial features (e.g., locations, regions)</li> <li>Spatial distribution plots (maps, heatmaps)</li> <li>Spatial autocorrelation or clustering (if applicable)</li> </ul>"},{"location":"data/exploratory-analysis/#temporal-analysis","title":"Temporal Analysis","text":"<ul> <li>Time range covered by the data</li> <li>Trends over time (line plots, seasonal decomposition)</li> <li>Temporal aggregation (daily, weekly, monthly summaries)</li> </ul>"},{"location":"data/exploratory-analysis/#spatio-temporal-patterns","title":"Spatio-Temporal Patterns","text":"<ul> <li>Analysis of how variables change over space and time</li> <li>Animated or faceted plots (if available)</li> </ul>"},{"location":"data/exploratory-analysis/#key-plots","title":"Key Plots","text":"<ul> <li>Insert or describe key plots used in the analysis:</li> <li>Histogram of main variable(s)</li> <li>Boxplot by region or time period</li> <li>Map visualizations (choropleth, scatter, heatmap)</li> <li>Time series plots</li> <li>Any interactive or animated plots (describe or link)</li> </ul>"},{"location":"data/exploratory-analysis/#insights","title":"Insights","text":"<ul> <li>Main findings from the exploratory analysis</li> <li>Notable patterns, anomalies, or trends</li> <li>Implications for further analysis or modeling </li> </ul>"},{"location":"experiments/model-evaluation/","title":"Results and Evaluation","text":""},{"location":"experiments/model-evaluation/#performance-metrics","title":"Performance Metrics","text":""},{"location":"experiments/model-evaluation/#classification-metrics","title":"Classification Metrics","text":"<ul> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>F1 Score</li> <li>ROC-AUC</li> <li>Confusion Matrix</li> </ul>"},{"location":"experiments/model-evaluation/#regression-metrics","title":"Regression Metrics","text":"<ul> <li>Mean Squared Error (MSE)</li> <li>Root Mean Squared Error (RMSE)</li> <li>Mean Absolute Error (MAE)</li> <li>R-squared</li> <li>Adjusted R-squared</li> </ul>"},{"location":"experiments/model-evaluation/#model-comparison","title":"Model Comparison","text":""},{"location":"experiments/model-evaluation/#baseline-models","title":"Baseline Models","text":"<p>Description of baseline models and their performance.</p>"},{"location":"experiments/model-evaluation/#advanced-models","title":"Advanced Models","text":"<p>Comparison of different model architectures and their performance.</p>"},{"location":"experiments/model-evaluation/#cross-validation-results","title":"Cross-Validation Results","text":"<p>Detailed results from k-fold cross-validation: - Mean performance - Standard deviation - Confidence intervals</p>"},{"location":"experiments/model-evaluation/#error-analysis","title":"Error Analysis","text":"<ul> <li>Common error patterns</li> <li>Error distribution</li> <li>Outlier analysis</li> </ul>"},{"location":"experiments/model-evaluation/#model-interpretability","title":"Model Interpretability","text":"<ul> <li>Feature importance</li> <li>SHAP values</li> <li>Partial dependence plots</li> <li>Decision paths (for tree-based models)</li> </ul>"},{"location":"experiments/model-evaluation/#model-robustness","title":"Model Robustness","text":"<ul> <li>Sensitivity analysis</li> <li>Stability testing</li> <li>Performance across different data subsets</li> </ul>"},{"location":"experiments/model-evaluation/#visualization","title":"Visualization","text":"<ul> <li>Performance curves</li> <li>Error plots</li> <li>Feature importance plots</li> <li>Residual analysis plots </li> </ul>"},{"location":"experiments/overview/","title":"Experiment Overview","text":""},{"location":"experiments/overview/#model-architecture","title":"Model Architecture","text":"<p>Our model implements a logistic regression classifier with L2 regularization. The loss function is defined as:</p> <p>$$ \\mathcal{L}(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m [y_i \\log(h_\\theta(x_i)) + (1-y_i)\\log(1-h_\\theta(x_i))] + \\frac{\\lambda}{2m}\\sum_{j=1}^n \\theta_j^2 $$</p> <p>Where: - $h_\\theta(x)$ is the sigmoid function: $h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}$ - $\\lambda$ is the regularization parameter - $m$ is the number of training examples - $n$ is the number of features</p>"},{"location":"experiments/overview/#training-process","title":"Training Process","text":"<p>The model is trained using the following steps:</p> <ol> <li>Data preprocessing</li> <li>Feature scaling</li> <li>Model training with gradient descent</li> <li>Model evaluation</li> </ol>"},{"location":"experiments/overview/#hyperparameters","title":"Hyperparameters","text":"Parameter Value Description learning_rate 0.01 Step size for gradient descent max_iter 1000 Maximum number of iterations lambda 0.1 L2 regularization strength"},{"location":"experiments/overview/#results","title":"Results","text":"<p>The model achieves the following performance metrics:</p> Metric Value Accuracy 0.85 Precision 0.83 Recall 0.87 F1 Score 0.85"},{"location":"experiments/overview/#visualization","title":"Visualization","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Example code for plotting results\nplt.figure(figsize=(10, 6))\nsns.heatmap(confusion_matrix, annot=True, fmt='d')\nplt.title('Confusion Matrix')\nplt.show()\n</code></pre>"},{"location":"experiments/overview/#next-steps","title":"Next Steps","text":"<ul> <li>[ ] Experiment with different regularization strengths</li> <li>[ ] Try feature engineering approaches</li> <li>[ ] Implement cross-validation</li> <li>[ ] Add more evaluation metrics </li> </ul>"}]}